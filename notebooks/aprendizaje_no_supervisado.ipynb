{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa987a3",
   "metadata": {},
   "source": [
    "# Aprendizaje no supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af012482",
   "metadata": {},
   "source": [
    "## 1. Importar bibliotecas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be491fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bebabd",
   "metadata": {},
   "source": [
    "## 2. Cargar el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542af26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establece tu ruta de trabajo\n",
    "import os\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbb95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruta = os.path.join('..', 'docs', 'datos', 'wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b6796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruta = os.path.join('drive', 'MyDrive', 'curso-machine-learning', 'wine.csv') #content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ruta)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3cb9c",
   "metadata": {},
   "source": [
    "> El conjunto de datos contiene 3 variables cuantitativas. Sobre características de vinos:\n",
    "> - ``Alcohol``\n",
    "> - ``Proline``\n",
    "> - ``flavanoids``\n",
    ">\n",
    "\n",
    "> **No contiene la variable objetivo**, ya que en el aprendizaje no supervisado no se cuenta con dicha variable.\n",
    "\n",
    "> Supongamos que estamos interesados en agrupar los datos en función de estas características. Para ello, podemos utilizar técnicas de **clustering como K-means**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c14048c",
   "metadata": {},
   "source": [
    "## K-means Clustering  \n",
    "\n",
    "Es un **algoritmo de aprendizaje no supervisado** que agrupa observaciones en **_k_ clusters** basándose en su similitud. \n",
    " \n",
    "Cada cluster se define por un **centroide** (el “promedio” de los puntos asignados a ese grupo).  \n",
    "\n",
    "\n",
    "### Idea principal\n",
    "- Queremos que los puntos dentro de un mismo cluster estén lo más **cercanos** posible al centroide.  \n",
    "- Y que los clusters estén lo más **separados** posible entre sí.  \n",
    "\n",
    "### Algoritmo paso a paso\n",
    "1. **Elegir k** (número de clusters).  \n",
    "2. **Inicializar centroides** (de forma aleatoria).  \n",
    "3. **Asignar puntos a clusters**:  \n",
    "   Cada punto se asigna al centroide más cercano usando distancia euclidiana:  \n",
    "\n",
    "   $$\n",
    "   d(x, \\mu_j) = \\sqrt{\\sum_i (x_i - \\mu_{j,i})^2}\n",
    "   $$\n",
    "\n",
    "4. **Actualizar centroides**:  \n",
    "\n",
    "* Una vez asignados los puntos, el nuevo centroide de cada cluster se obtiene como el promedio de todos los puntos en ese cluster.\n",
    "\n",
    "* Es decir, el centroide “se mueve” hacia el centro real de los puntos que lo rodean.\n",
    "\n",
    "5. **Iterar** pasos 3 y 4 hasta que los centroides ya no cambien (o hasta un número máximo de iteraciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285c7ff",
   "metadata": {},
   "source": [
    "![kmeans-convergence](../docs/_static/512px-K-means_convergence.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7222a13d",
   "metadata": {},
   "source": [
    "**Figura 1:** Convergencia del algoritmo K-means. Fuente: [Wikipedia](https://commons.wikimedia.org/wiki/File:K-means_convergence.gif). Chire, CC BY-SA 4.0 <https://creativecommons.org/licenses/by-sa/4.0>, via Wikimedia Commons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72807bbe",
   "metadata": {},
   "source": [
    "### Función objetivo\n",
    "K-means minimiza la **suma de distancias cuadradas** entre puntos y sus centroides:\n",
    "\n",
    "$$\n",
    "J = \\sum_{j=1}^k \\sum_{x \\in C_j} \\| x - \\mu_j \\|^2\n",
    "$$\n",
    "\n",
    "- $C_j$ = conjunto de puntos del cluster $j$  \n",
    "- $\\mu_j$ = centroide del cluster $j$\n",
    "\n",
    "K-Means suma todas esas distancias (al cuadrado) y trata de que el total sea lo más pequeño posible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5011fab",
   "metadata": {},
   "source": [
    "## 3. Características de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16450c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad9c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Histogramas ---#\n",
    "for col in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(6,3))\n",
    "    sns.histplot(df[col],\n",
    "                 kde=True, \n",
    "                 bins=20, \n",
    "                 ax=ax, \n",
    "                 color='purple', \n",
    "                 alpha=0.4)\n",
    "    ax.set_title(f\"Distribución de {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b368b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Boxplots ---#\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(data=df)\n",
    "plt.title(\"Boxplots de variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pairplot ---#\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d429a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Matriz de correlación ---#\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Matriz de correlación\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee162a",
   "metadata": {},
   "source": [
    "Recordemos que la matriz de correlación nos ayuda a observar dos cosas importantes:\n",
    "\n",
    "* La **magnitud** de la correlación entre variables (qué tan fuerte es la relación).\n",
    "* La **dirección** de la correlación (si es positiva o negativa).\n",
    "\n",
    "También es una buena herramienta para detectar **multicolinealidad** (cuando dos o más variables están altamente correlacionadas entre sí)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c319341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# --- Scatter 3D (aun sin clusterizar) ---#\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df['flavanoids'], df['alcohol'], df['proline'])\n",
    "\n",
    "ax.set_xlabel('Flavanoids')\n",
    "ax.set_ylabel('Alcohol')\n",
    "ax.set_zlabel('Proline')\n",
    "\n",
    "plt.title(\"Scatter 3D de las variables originales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d66578",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f4637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Escalamiento de datos --- #\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ee02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#StandardScaler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7fd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Boxplots de datos escalados ---#\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(data=df_scaled)\n",
    "plt.title(\"Boxplots de variables (escaladas)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282200c",
   "metadata": {},
   "source": [
    "## Previas para conocer k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de aplicar KMeans, debemos elegir el número de clusters (k)\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sum_distancias = []\n",
    "ks = range(1, 11) # Probamos k desde 1 hasta 10\n",
    "\n",
    "for k in ks:\n",
    "    modelo = KMeans(n_clusters=k, random_state=42, n_init=11)\n",
    "    modelo.fit(X_scaled)\n",
    "    sum_distancias.append(modelo.inertia_) # Guardamos la suma de distancias de cada punto a su centroide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8292b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Graficar el codo ---#\n",
    "plt.plot(ks, sum_distancias, marker='o')\n",
    "plt.xlabel(\"Número de clusters (k)\")\n",
    "plt.ylabel(\"Suma de distancias a los centroides\")\n",
    "plt.title(\"Método del codo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e3c7e",
   "metadata": {},
   "source": [
    "Además del _método del codo_, hay una métrica que nos ayuda a complementar nuestro análisis para elegir el número óptimo de clusters: el **_silhouette score_**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1874f90",
   "metadata": {},
   "source": [
    "## 📊 Silhouette Analysis\n",
    "\n",
    "El **silhouette analysis** se puede usar para estudiar la distancia de separación entre los clusters resultantes.  \n",
    "\n",
    "El **silhouette plot** muestra qué tan cerca está cada punto de un cluster respecto a los puntos de los clusters vecinos.  \n",
    "\n",
    "De esta manera, ofrece una forma visual de evaluar parámetros como el **número de clusters**.\n",
    "\n",
    "\n",
    "### Intuición\n",
    "\n",
    "El coeficiente de silhouette para un punto $i$ se define como:\n",
    "\n",
    "$$\n",
    "s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}}\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $a(i)$ = distancia promedio del punto $i$ a todos los puntos de su propio cluster (**cohesión**).  \n",
    "- $b(i)$ = distancia promedio del punto $i$ al cluster vecino más cercano (**separación**).  \n",
    "\n",
    "El valor resultante está en el rango $[-1, 1]$.\n",
    "\n",
    "### Interpretación\n",
    "\n",
    "- **Cerca de +1** → el punto está bien asignado, lejos de los clusters vecinos.  \n",
    "- **≈ 0** → el punto se encuentra en la frontera entre dos clusters.  \n",
    "- **Negativo (< 0)** → el punto podría estar mal asignado (más cerca de otro cluster que del suyo).\n",
    "\n",
    "Puedes revisar la documentación oficial de Silhouette Score en [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42a816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Evalúa k candidatos del codo\n",
    "for k in [2, 3, 4]:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    print(f\"k={k}, silhouette={sil:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda96fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "def plot_silhouette(X, k=3, ax=None):\n",
    "    # Ajustar modelo\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "    labels = km.fit_predict(X)\n",
    "\n",
    "    # Calcular coeficientes de silhouette\n",
    "    sil_avg = silhouette_score(X, labels)\n",
    "    sil_values = silhouette_samples(X, labels)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(k):\n",
    "        cluster_sil = sil_values[labels == i]\n",
    "        cluster_sil.sort()\n",
    "        size_cluster = cluster_sil.shape[0]\n",
    "        y_upper = y_lower + size_cluster\n",
    "\n",
    "        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_sil, alpha=0.7)\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster, str(i))\n",
    "        y_lower = y_upper + 10\n",
    "\n",
    "    ax.axvline(x=sil_avg, color=\"red\", linestyle=\"--\")\n",
    "    ax.set_title(f\"Silhouette plot (k={k}, avg={sil_avg:.3f})\")\n",
    "    ax.set_xlabel(\"Coeficiente silhouette\")\n",
    "    ax.set_ylabel(\"Cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bbd9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_silhouette(X_scaled, k=2, ax=axes[0])\n",
    "plot_silhouette(X_scaled, k=3, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44705c42",
   "metadata": {},
   "source": [
    "## Modelo K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60116870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# KMeans con k=3\n",
    "k = 3\n",
    "mi_modelo = KMeans(n_clusters=k,\n",
    "                random_state=42, \n",
    "                n_init=10)\n",
    "\n",
    "# Generamos nueva col para identificar el clúster\n",
    "df[\"cluster\"] = mi_modelo.fit_predict(X_scaled)                \n",
    "\n",
    "labels = mi_modelo.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76852f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centroides en el espacio escalado\n",
    "centroides = mi_modelo.cluster_centers_\n",
    "centroides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6e7334",
   "metadata": {},
   "source": [
    "## Visualización de clústers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6896cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(7,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df[\"flavanoids\"], df[\"alcohol\"], df[\"proline\"],\n",
    "           c=df[\"cluster\"], cmap=\"viridis\", s=50, alpha=0.7)\n",
    "\n",
    "# centroides en las variables originales\n",
    "centroides_orig = scaler.inverse_transform(centroides)\n",
    "ax.scatter(centroides_orig[:, df.columns.get_loc(\"flavanoids\")],\n",
    "           centroides_orig[:, df.columns.get_loc(\"alcohol\")],\n",
    "           centroides_orig[:, df.columns.get_loc(\"proline\")],\n",
    "           c=\"red\", marker=\"X\", s=200, label=\"Centroides\")\n",
    "\n",
    "ax.set_xlabel(\"Flavanoids\")\n",
    "ax.set_ylabel(\"Alcohol\")\n",
    "ax.set_zlabel(\"Proline\")\n",
    "plt.title(\"Clústers K-means con k=3\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5679a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico 3D interactivo\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df_plot = df.copy()\n",
    "df_plot['cluster'] = labels.astype(str)  \n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    df_plot,\n",
    "    x='flavanoids', y='alcohol', z='proline',\n",
    "    color='cluster',\n",
    "    size=[3]*len(df_plot),        \n",
    "    title='Wine + K-means (3D)'\n",
    ")\n",
    "\n",
    "centroids_orig = scaler.inverse_transform(mi_modelo.cluster_centers_)\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=centroids_orig[:, 0],\n",
    "    y=centroids_orig[:, 1],\n",
    "    z=centroids_orig[:, 2],\n",
    "    mode='markers+text',\n",
    "    marker=dict(size=5, symbol='x'),     \n",
    "    text=[f'C{i}' for i in range(centroids_orig.shape[0])],\n",
    "    textposition='top center',\n",
    "    name='Centroides'\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccd292e",
   "metadata": {},
   "source": [
    "## Nuevos datos con modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f38bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que tenemos nuevos vinos (valores sin escalar)\n",
    "nuevos = [[2.0, 13.5, 750],   # (flavanoids, alcohol, proline)\n",
    "          [1.0, 12.0, 400]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero escalamos con el mismo scaler\n",
    "scaler = StandardScaler()\n",
    "nuevos_scaled = scaler.fit_transform(nuevos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce8f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos su clúuster (nota que usamos el modelo ya entrenado [llamado: mi_modelo])\n",
    "pred_nuevos = mi_modelo.predict(nuevos_scaled)\n",
    "pred_nuevos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Graficar ---#\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(X_scaled[:,0], X_scaled[:,1], c=labels, cmap=\"viridis\", alpha=0.6, s=40, label=\"Datos originales\")\n",
    "\n",
    "# centroides\n",
    "plt.scatter(mi_modelo.cluster_centers_[:,0], mi_modelo.cluster_centers_[:,1], \n",
    "            c=\"red\", marker=\"X\", s=200, label=\"Centroides\")\n",
    "\n",
    "# nuevos puntos\n",
    "plt.scatter(nuevos_scaled[:,0], nuevos_scaled[:,1],\n",
    "            c=pred_nuevos, cmap=\"viridis\", edgecolors=\"k\", s=200, marker=\"o\", label=\"Nuevos puntos\")\n",
    "\n",
    "plt.xlabel(\"Flavanoids (escalado)\")\n",
    "plt.ylabel(\"Alcohol (escalado)\")\n",
    "plt.title(\"K-means con nuevos puntos asignados\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-curso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
