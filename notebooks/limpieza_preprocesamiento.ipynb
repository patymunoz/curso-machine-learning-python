{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7677f2",
   "metadata": {},
   "source": [
    "# Limpieza y preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b8af8",
   "metadata": {},
   "source": [
    "## ¬øQu√© es limpieza de datos?\n",
    "\n",
    "La _limpieza de datos_ es el proceso de identificar y corregir (o eliminar) errores y inconsistencias en los datos para mejorar su calidad.\n",
    "\n",
    "Incluye tareas como:\n",
    "\n",
    "* Manejo de valores faltantes\n",
    "* Remover valores duplicados\n",
    "* Corregir valores err√≥neos o inconsistentes\n",
    "* Estandarizar formatos\n",
    "* Manejo de valores at√≠picos (outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52902043",
   "metadata": {},
   "source": [
    "## ¬øQu√© es preprocesamiento de datos?\n",
    "\n",
    "El _preprocesamiento de datos_ es el proceso de transformar y preparar los datos brutos para que sean adecuados para el an√°lisis o modelado.\n",
    "\n",
    "Incluye tareas como:\n",
    "\n",
    "* Escalado y normalizaci√≥n de datos\n",
    "* Codificaci√≥n de variables categ√≥ricas\n",
    "* Reducci√≥n de dimensionalidad\n",
    "* Separar data en train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c105e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb0b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3fb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"titanic\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75816ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab900cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pclass.unique() #class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2095c55",
   "metadata": {},
   "source": [
    "##### üîπ Conocer el tipo de variable y valores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452b433",
   "metadata": {},
   "source": [
    "| variable      | tipo de variable                     | descripci√≥n breve                                      | ejemplos de valores |\n",
    "|---------------|--------------------------------------|--------------------------------------------------------|---------------------|\n",
    "| survived      | cualitativa dicot√≥mica (binaria)     | indica si sobrevivi√≥ (1) o no (0)                      | `0`, `1` |\n",
    "| pclass        | cualitativa ordinal                  | clase del pasajero (nivel socioecon√≥mico)              | `1`, `2`, `3` |\n",
    "| sex           | cualitativa nominal                  | sexo biol√≥gico del pasajero                            | `\"male\"`, `\"female\"` |\n",
    "| age           | cuantitativa continua (ratio)        | edad en a√±os                                           | `22.0`, `35.0`, `nan` |\n",
    "| sibsp         | cuantitativa discreta                | n√∫mero de hermanos/esposos a bordo                     | `0`, `1`, `3` |\n",
    "| parch         | cuantitativa discreta                | n√∫mero de padres/hijos a bordo                         | `0`, `1`, `2` |\n",
    "| fare          | cuantitativa continua (ratio)        | tarifa pagada                                          | `7.25`, `71.28`, `512.33` |\n",
    "| embarked      | cualitativa nominal                  | puerto de embarque (c, q, s)                           | `\"s\"`, `\"c\"`, `\"q\"` |\n",
    "| class         | cualitativa ordinal (categor√≠a)      | clase en texto                                         | `\"first\"`, `\"second\"`, `\"third\"` |\n",
    "| who           | cualitativa nominal                  | tipo de persona                                        | `\"man\"`, `\"woman\"`, `\"child\"` |\n",
    "| adult_male    | cualitativa dicot√≥mica (binaria)     | indica si es hombre adulto                             | `True`, `False` |\n",
    "| deck          | cualitativa nominal (muchos nulos)   | letra de la cubierta                                   | `\"c\"`, `\"e\"`, `nan` |\n",
    "| embark_town   | cualitativa nominal                  | ciudad de embarque                                     | `\"southampton\"`, `\"cherbourg\"`, `\"queenstown\"` |\n",
    "| alive         | cualitativa dicot√≥mica (binaria)     | estado de supervivencia en texto                       | `\"yes\"`, `\"no\"` |\n",
    "| alone         | cualitativa dicot√≥mica (binaria)     | indica si viajaba solo                                 | `True`, `False` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4933c3",
   "metadata": {},
   "source": [
    "## Comencemos por la limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a2d5fd",
   "metadata": {},
   "source": [
    "##### üîπValores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf668f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores faltantes\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdffbdb",
   "metadata": {},
   "source": [
    "Cuando tenemos valores faltantes en un dataset, podemos manejarlos de varias maneras:\n",
    "\n",
    "* Eliminar filas o columnas con valores faltantes\n",
    "* Imputar valores faltantes con la media, mediana o moda\n",
    "* Usar modelos predictivos para estimar los valores faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890cb35",
   "metadata": {},
   "source": [
    "**OJO**: **Nunca debemos imputar valores faltantes con la media, mediana o moda sin antes analizar si la variable tiene una distribuci√≥n normal o sesgada. Tambi√©n es importante considerar que este paso requiere su debida atenci√≥n, ya que puede introducir sesgos en el an√°lisis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba210a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: Imputar variable \"Age\" condicionada a \"Pclass\" y \"Sex\"\n",
    "\n",
    "age_median = df.groupby(['pclass', 'sex'])['age'].median()\n",
    "age_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_age(row):\n",
    "    if pd.isna(row[\"age\"]):\n",
    "        return age_median.loc[row[\"pclass\"], row[\"sex\"]]\n",
    "    return row[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8201d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"] = df.apply(impute_age, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2784d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da862e8",
   "metadata": {},
   "source": [
    "_¬øQu√© piensas del siguiente ejemplo? ¬øLo imputar√≠as de esta manera?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66435316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar por moda\n",
    "df[\"embarked\"].fillna(df[\"embarked\"].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0060443b",
   "metadata": {},
   "source": [
    "##### üîπ Valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores duplicados\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0662fdf",
   "metadata": {},
   "source": [
    "Cuando trabajamos con `.duplicate()` podemos encontrar filas duplicadas en un DataFrame.\n",
    "\n",
    "```python\n",
    "   Nombre  Edad\n",
    "0     Ana    25\n",
    "1    Luis    30\n",
    "2     Ana    25\n",
    "3  Carlos    40\n",
    "\n",
    "0    False\n",
    "1    False\n",
    "2     True   <- duplicado de la fila 0\n",
    "3    False\n",
    "dtype: bool\n",
    "\n",
    "1   <- hay un duplicado\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91152aa",
   "metadata": {},
   "source": [
    "A menos que podamos justificar la presencia de filas duplicadas, generalmente es una buena pr√°ctica eliminarlas para evitar sesgos en el an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52645867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b223e640",
   "metadata": {},
   "source": [
    "##### üîπ Estandarizar formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"] = df[\"sex\"].str.lower()  \n",
    "df[\"embarked\"] = df[\"embarked\"].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44461045",
   "metadata": {},
   "source": [
    "##### üîπTratar _outliers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca5d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "# Boxplot\n",
    "ax[0].boxplot(df[\"fare\"], vert=False)\n",
    "ax[0].set_title(\"Fare - Antes (boxplot)\")\n",
    "\n",
    "# Histograma\n",
    "ax[1].hist(df[\"fare\"], bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "ax[1].set_title(\"Fare - Antes (histograma)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los l√≠mites con IQR\n",
    "Q1 = df[\"fare\"].quantile(0.25)   # primer cuartil (25%)\n",
    "Q3 = df[\"fare\"].quantile(0.75)   # tercer cuartil (75%)\n",
    "IQR = Q3 - Q1                    # rango intercuart√≠lico\n",
    "\n",
    "lower = Q1 - 1.5 * IQR            # l√≠mite inferior\n",
    "upper = Q3 + 1.5 * IQR            # l√≠mite superior\n",
    "\n",
    "print(f\"L√≠mite inferior: {lower:.2f}\")\n",
    "print(f\"L√≠mite superior: {upper:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92266ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "ax.hist(df[\"fare\"], bins=30, color=\"skyblue\", edgecolor=\"black\")\n",
    "ax.axvline(lower, color=\"green\", linestyle=\"--\", linewidth=2, label=f\"L√≠mite inferior = {lower:.2f}\")\n",
    "ax.axvline(upper, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"L√≠mite superior = {upper:.2f}\")\n",
    "\n",
    "ax.set_title(\"Distribuci√≥n de fare con l√≠mites IQR\")\n",
    "ax.set_xlabel(\"Fare\")\n",
    "ax.set_ylabel(\"Frecuencia\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf17dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcci√≥n\n",
    "lower = max(0, Q1 - 1.5*IQR)  # el m√≠nimo l√≥gico es 0\n",
    "print(f\"L√≠mite inferior: {lower:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplaza valores \n",
    "df[\"fare\"] = df[\"fare\"].clip(lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca57782",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "ax[0].boxplot(df[\"fare\"], vert=False)\n",
    "ax[0].set_title(\"Fare - Despu√©s (boxplot)\")\n",
    "\n",
    "ax[1].hist(df[\"fare\"], bins=30, color=\"lightgreen\", edgecolor=\"black\")\n",
    "ax[1].set_title(\"Fare - Despu√©s (histograma)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b744f31",
   "metadata": {},
   "source": [
    "**OJO: La forma de manejar los _outliers_ depende del contexto y del an√°lisis que se vaya a realizar. No existe una √∫nica soluci√≥n correcta.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110a7f72",
   "metadata": {},
   "source": [
    "## Sigamos con el preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a432378",
   "metadata": {},
   "source": [
    "El preprocesamiento de datos **no es un conjunto de pasos fijos**, sino que depende de:\n",
    "\n",
    "1. **El algoritmo de Machine Learning que vamos a usar**  \n",
    "   - Algunos algoritmos **son sensibles a la escala** (ej: regresi√≥n log√≠stica, SVM, KNN, redes neuronales).  \n",
    "     ‚Üí Necesitan escalado o normalizaci√≥n.  \n",
    "   - Otros algoritmos **no lo necesitan** (ej: √°rboles de decisi√≥n, random forest, gradient boosting).  \n",
    "     ‚Üí Pueden trabajar con variables en distintas escalas sin problema.\n",
    "\n",
    "2. **El tipo de problema**  \n",
    "   - Si tengo muchas variables categ√≥ricas con muchas categor√≠as ‚Üí One-Hot Encoding puede generar demasiadas columnas, mejor usar *target encoding* o *embeddings*.  \n",
    "   - Si el dataset tiene muchas variables correlacionadas ‚Üí PCA u otra t√©cnica de reducci√≥n de dimensionalidad puede ser √∫til.  \n",
    "\n",
    "3. **El objetivo final**  \n",
    "   - Predecir con m√°xima precisi√≥n.  \n",
    "   - Hacer un modelo interpretable.  \n",
    "   - Reducir tiempo de c√≥mputo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506da2b9",
   "metadata": {},
   "source": [
    "En este sentido, y para que el ejemplo sea m√°s real, supongamos que nos plantemos lo siguiente:\n",
    "\n",
    "_Podemos predicir si un pasajero sobrevivi√≥ o no al naufragio del Titanic, usando caracter√≠sticas (edad, sexo, clase,etc) como variables predictoras?_\n",
    "\n",
    "Aqu√≠ estamos hablando de un **problema de clasificaci√≥n.**\n",
    "\n",
    "* Variable objetivo: `survived` (0 = no sobrevivi√≥, 1 = sobrevivi√≥)\n",
    "* Variables predictoras: `pclass`, `sex`, `age`, `sibsp`, `parch`, `fare`, `adult_male`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844ba62",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7eb55c",
   "metadata": {},
   "source": [
    "#### T√©cnicas de preprocesamiento que tienen sentido en este caso\n",
    "\n",
    "1. Valores categ√≥ricos: `sex`\n",
    "    * Necesitans ser convertidos a variables num√©ricas.\n",
    "    * T√©cnicas: One-Hot Encoding, Label Encoding, Target Encoding.\n",
    "\n",
    "2. Escalado de variables num√©ricas: `age`, `fare`\n",
    "    * Si usamos modelos como _Regresi√≥n log√≠stica_ o _SVM_, el escalado es importante porque dependen de las distancias y magnitudes.\n",
    "    * Si usamos _√°rboles de decisi√≥n_ o _random forest_, el escalado no es tan cr√≠tico.\n",
    "    * T√©cnicas: Min-Max Scaling, Standardization (Z-score), Robust Scaling.\n",
    "\n",
    "3. Separaci√≥n en _train/test_\n",
    "    * Es fundamental para evaluar el rendimiento del modelo en datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ab719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir X e y\n",
    "X = df[[\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"adult_male\"]]\n",
    "y = df[\"survived\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c091ea",
   "metadata": {},
   "source": [
    "Separamos los datos en conjuntos de entrenamiento (80%) y prueba (20%) para evaluar el modelo de manera justa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500df05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir columnas num√©ricas y categ√≥ricas\n",
    "num_cols = [\"age\", \"sibsp\", \"parch\", \"fare\"]\n",
    "cat_cols = [\"sex\", \"pclass\"]\n",
    "bin_cols = [\"adult_male\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768e4a4",
   "metadata": {},
   "source": [
    "   - **Num√©ricas** ‚Üí `StandardScaler` para escalar a media 0 y varianza 1.\n",
    "   - **Categ√≥ricas** ‚Üí `OneHotEncoder(drop=\"first\")` para convertir categor√≠as en variables dummy.\n",
    "   - **Binaria (`adult_male`)** ‚Üí `passthrough`, se deja igual porque ya est√° en formato 0/1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\"), cat_cols),\n",
    "        (\"bin\", \"passthrough\", bin_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdfedab",
   "metadata": {},
   "source": [
    "Se construy√≥ un `Pipeline` que aplica el preprocesamiento definido y luego entrena una **Regresi√≥n Log√≠stica**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1594b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline con regresi√≥n log√≠stica\n",
    "log_reg = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=10000))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344c8db",
   "metadata": {},
   "source": [
    "El modelo se entren√≥ con los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba8dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b77c0",
   "metadata": {},
   "source": [
    "Se evalu√≥ en los datos de prueba usando **accuracy** y m√©tricas de clasificaci√≥n (precisi√≥n, recall, F1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21961c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluaci√≥n\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-curso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
